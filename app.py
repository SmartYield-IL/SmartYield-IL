import streamlit as st
import pandas as pd
import requests
from bs4 import BeautifulSoup
import re

# --- ×”×’×“×¨×ª ×¢××•×“ ---
st.set_page_config(page_title="Debug Mode", layout="wide")
st.markdown("""<style>body { direction: rtl; text-align: right; font-family: 'Segoe UI'; }</style>""", unsafe_allow_html=True)

# --- ×‘×“×™×§×ª ××¤×ª×— (×“×™×‘××’) ---
def get_api_key():
    if "ZENROWS_KEY" in st.secrets:
        key = st.secrets["ZENROWS_KEY"]
        # ×‘×“×™×§×” ×©×”××¤×ª×— ×œ× ×¨×™×§
        if len(key) > 10:
            return key
    return None

def fetch_data_debug(target_url):
    api_key = get_api_key()
    
    # ×‘×“×™×§×” 1: ×”×× ×”××¤×ª×— ×§×™×™×?
    if not api_key:
        st.error("âŒ ×©×’×™××” 1: ×”××¢×¨×›×ª ×œ× ××¦×œ×™×—×” ×œ×§×¨×•× ××ª ×”××¤×ª×— ××”-Secrets. ×•×•×“× ×©×¢×©×™×ª Save ×•-Reboot.")
        return None
    
    st.info(f"âœ… ××¤×ª×— ×–×•×”×” (××ª×—×™×œ ×‘: {api_key[:4]}...)")
    st.info(f"ğŸ“¡ ×× ×¡×” ×œ×”×ª×—×‘×¨ ×œ×›×ª×•×‘×ª: {target_url}")

    proxy_url = "https://api.zenrows.com/v1/"
    params = {
        "apikey": api_key,
        "url": target_url,
        "js_render": "true",
        "premium_proxy": "true",
        "country": "il"
    }
    
    try:
        response = requests.get(proxy_url, params=params, timeout=60)
        
        # ×‘×“×™×§×” 2: ××” ×”×©×¨×ª ×¢× ×”?
        st.write(f"ğŸ”„ ×§×•×“ ×ª×©×•×‘×” ××”×©×¨×ª: {response.status_code}")
        
        if response.status_code == 200:
            st.success("âœ… ×”×—×™×‘×•×¨ ×”×¦×œ×™×—! ×”×ª×§×‘×œ HTML.")
            # ×‘×“×™×§×” 3: ×”×× ×§×™×‘×œ× ×• ×“×£ ×¨×™×§?
            if len(response.text) < 500:
                st.warning("âš ï¸ ×”×ª×§×‘×œ ×“×£ ×§×¦×¨ ××“×™ (×—×©×“ ×œ×—×¡×™××”).")
                st.code(response.text) # ×”×¦×’×ª ×”×ª×•×›×Ÿ ×”×’×•×œ××™
            return response.text
        else:
            st.error(f"âŒ ×©×’×™××” ××”×©×¨×ª: {response.text}")
            return None
            
    except Exception as e:
        st.error(f"âŒ ×©×’×™××” ×‘×—×™×‘×•×¨ Python: {str(e)}")
        return None

def parse_results(html):
    soup = BeautifulSoup(html, 'html.parser')
    # ×‘×“×™×§×” 4: ×”×× ×™×© ×‘×›×œ×œ ×¤×¨×™×˜×™× ×‘×“×£?
    items = soup.find_all('div', class_=re.compile(r'(feeditem|feed_item|feed-item)', re.IGNORECASE))
    st.write(f"ğŸ§ ×”×× ×ª×— ××¦× {len(items)} ××œ×× ×˜×™× ×©×œ ××•×“×¢×•×ª ×‘-HTML.")
    
    results = []
    for item in items:
        try:
            txt = item.get_text(" ", strip=True)
            price = 0
            p_match = re.search(r'(\d{1,3}(?:,\d{3})*)\s*â‚ª', txt)
            if p_match: price = int(p_match.group(1).replace(',', ''))
            
            # ×‘×“×™×§×” 5: ×”×× ×”××—×™×¨ ×”×’×™×•× ×™?
            if price < 100000: continue

            link = "#"
            a_tag = item.find('a', href=True)
            if a_tag:
                href = a_tag['href']
                link = f"https://www.yad2.co.il{href}" if href.startswith("/") else href

            address = "×œ× ×¦×•×™×Ÿ"
            sub = item.find(class_="subtitle")
            if sub: address = sub.get_text(strip=True)

            sqm = 0
            s_m = re.finditer(r'(\d{2,4})\s*(?:×"×¨|××¨|××˜×¨)', txt)
            for m in s_m:
                val = int(m.group(1))
                if 30 < val < 500: sqm = val; break
            
            ppm = int(price / sqm) if sqm > 0 else 0
            results.append({"address": address, "price": price, "sqm": sqm, "ppm": ppm, "link": link})
        except: continue
    return results

# --- ×××©×§ ---
st.title("ğŸ› ï¸ Debug Mode")

if st.button("×‘×¦×¢ ×‘×“×™×§×” ×¢×œ × ×ª× ×™×” (×”××¨×“-×§×•×“)"):
    # ×©×™××•×© ×‘×œ×™× ×§ ×§×‘×•×¢ ×œ× ×ª× ×™×” ×›×“×™ ×œ× ×˜×¨×œ ×‘×¢×™×•×ª ×‘×‘× ×™×™×ª ×”×œ×™× ×§
    test_url = "https://www.yad2.co.il/realestate/forsale?city=7400&rooms=3-4"
    
    html = fetch_data_debug(test_url)
    
    if html:
        data = parse_results(html)
        if data:
            st.dataframe(pd.DataFrame(data))
        else:
            st.warning("×”-HTML ×”×ª×§×‘×œ ××‘×œ ×œ× ×”×¦×œ×—× ×• ×œ×—×œ×¥ ××× ×• ×“×™×¨×•×ª.")
